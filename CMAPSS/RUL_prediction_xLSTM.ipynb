{"cells":[{"cell_type":"markdown","metadata":{},"source":["## Test of the xLstm"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["模型内存占用: 71.10546875 M\n","kan代码运行时间: 1.0109071731567383 秒\n","模型的参数数量: 18203 个\n","torch.Size([64, 1])\n"]}],"source":["import torch\n","import torch.nn as nn\n","from xlstm import KANmLSTMBlock,KANxLSTM\n","import time\n","import numpy as np\n","class Net(nn.Module):\n","    def __init__(self):\n","        super(Net, self).__init__()\n","\n","        self.lstm1 =  KANxLSTM(14, 2, 1, \"ms\", batch_first=True, proj_factor_slstm=4/3, proj_factor_mlstm=2) #input_size, head_size, num_heads, proj_factor=2\n","\n","        self.fc1 = nn.Linear(420, 32)\n","        self.dr = nn.Dropout(0.5)\n","        self.fc3 = nn.Linear(32, 1)\n","\n","    def forward(self, x):\n","        x, _ = self.lstm1(x)\n","        #print(x.shape)\n","        x = torch.tanh(x.reshape(x.shape[0], -1))\n","        x = self.dr(x)\n","        x = self.fc1(x)\n","\n","        x = torch.relu(x)\n","        x = self.fc3(x)\n","        return x\n","\n","    \n","def get_model_memory_usage(model):\n","    mem_usage = 0\n","    for param in model.parameters():\n","        mem_usage += np.prod(list(param.size())) * param.element_size()\n","        \n","    return mem_usage\n","def count_parameters(model):\n","    return sum(p.numel() for p in model.parameters())\n","x = torch.randn(64, 30, 14).to(\"cuda\")\n","model = Net().to(\"cuda\")\n","\n","start = time.time()\n","\n","out = model(x)\n","\n","end_time = time.time()  # 再次获取当前时间\n","\n","elapsed_time = end_time - start  # 计算经过的时间\n","mem_usage = get_model_memory_usage(model)\n","print(f\"模型内存占用: {mem_usage/1024} M\")\n","print(f\"kan代码运行时间: {elapsed_time} 秒\")\n","print(f\"模型的参数数量: {count_parameters(model)} 个\")\n","print(out.shape)\n"]},{"cell_type":"markdown","metadata":{"id":"NPOoYUmT_O_v"},"source":["## RUL prediction using Long Short Term Memory (LSTM) FD001\n","\n","In this notebook, we will use LSTM to predict RUL of NASA's turbofan engine dataset FD001. We will show the implementation without going into the theory of LSTM. Readers who want to get an intuitive understanding of LSTMs, should read [this excellent blog](https://colah.github.io/posts/2015-08-Understanding-LSTMs/) by Chris Olah."]},{"cell_type":"code","execution_count":9,"metadata":{"id":"64HJknqB_O_x"},"outputs":[],"source":["\n","\n","import numpy as np\n","import pandas as pd\n","import sklearn\n","from sklearn.model_selection import train_test_split\n","\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.metrics import mean_squared_error\n","import matplotlib.pyplot as plt\n","\n","np.random.seed(34)"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1689020245139,"user":{"displayName":"Alberto Moccardi","userId":"09120262365331070077"},"user_tz":-120},"id":"Vf5lFAQE_O_y","outputId":"f79da8d3-97cf-41e5-b8be-34207d72486a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Numpy version:  1.24.4\n","Pandas version:  2.0.3\n","Scikit-learn version:  1.3.0\n"]}],"source":["\n","print(\"Numpy version: \", np.__version__)\n","print(\"Pandas version: \", pd.__version__)\n","print(\"Scikit-learn version: \", sklearn.__version__)"]},{"cell_type":"markdown","metadata":{"id":"F8ex1m2U_O_y"},"source":["#### Data Preprocessing\n","\n","We strongly encourage readers to go through the [dataset description and prreprocessing notebook](https://github.com/biswajitsahoo1111/rul_codes_open/blob/master/notebooks/cmapss_notebooks/CMAPSS_data_description_and_preprocessing.ipynb). In that notebook we have explained how data preprocessing functions work with simple examples. In this notebook we will only use those functions. So prior familiarity with these functions is an advantage. Below are the parameters that we will use for data preprocessing:\n","\n","* Degradation model: Piecewise linear\n","* Early RUL: 125\n","* Window length: 30\n","* Shift: 1\n","* Data scaling: Standard scaling and Full dataset scaling.\n","\n","We will calculate two prediction scores on test data. In one case, we will take last 5 examples of test data for engine, calculate their predictions, and finally average those for each engine. In the second case, we will take only the last example of each engine and make predictions. The logic behind taking last 5 examples and averaging their predictions is to make the prediction robust against outliers. Due to some external factor, if our last example happens to be corrupted, its prediction outcome might be far off from the actual one. But if we average predictions from last 5 examples, we will get a more conservative estimate.\n","\n","In the following cell we will show boxplots of each column of training data. That will give us an idea about the values in different columns. If all the values in a column are constant, we drop those columns from our analysis.\n","\n","Readers can download the data from [here](https://ti.arc.nasa.gov/tech/dash/groups/pcoe/prognostic-data-repository/#turbofan). In the following cells, wherever data are read from a folder, readers should change the string to point to the respective folder from their system to run this notebook seamlessly."]},{"cell_type":"code","execution_count":11,"metadata":{"id":"t5CYzWwAssce"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","\n","from sklearn.linear_model import LinearRegression\n","from sklearn.metrics import mean_squared_error, r2_score\n","\n","%matplotlib inline"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"MC7FHKyAaZPN"},"outputs":[],"source":["\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import os\n","\n","# Setting seed for reproducibility\n","np.random.seed(1234)\n","PYTHONHASHSEED = 0\n","from sklearn.metrics import mean_absolute_error\n","\n","from sklearn.metrics import mean_absolute_percentage_error\n","from sklearn import preprocessing\n","from sklearn.metrics import confusion_matrix, recall_score, precision_score\n"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2208,"status":"ok","timestamp":1689020250466,"user":{"displayName":"Alberto Moccardi","userId":"09120262365331070077"},"user_tz":-120},"id":"HUeAA3M8aeGS","outputId":"e5dcdb09-895d-41ee-9ffa-25841329bc41"},"outputs":[],"source":["import os\n","import pandas as pd\n","\n","# Prompt the user for the flight condition\n","flight_condition = input(\"Please enter the flight condition (1-4): \")\n","\n","# Validate the user input\n","while flight_condition not in ['1', '2', '3', '4']:\n","    print(\"Invalid input. Please try again.\")\n","    flight_condition = input(\"Please enter the flight condition (1-4): \")\n","\n","# Set the file names based on the flight condition\n","train_file = f'train_FD00{flight_condition}.txt'\n","test_file = f'test_FD00{flight_condition}.txt'\n","rul_file = f'RUL_FD00{flight_condition}.txt'\n","\n","# Load the train dataset as a dataframe\n","train_dataset_path = os.path.join('./Data', train_file)\n","train_data = pd.read_csv(train_dataset_path, delimiter='\\s+', header=None)\n","\n","# Load the test dataset as a dataframe\n","test_dataset_path = os.path.join('./Data', test_file)\n","test_data = pd.read_csv(test_dataset_path, delimiter='\\s+', header=None)\n","\n","# Load the RUL dataset as a dataframe\n","rul_dataset_path = os.path.join('./Data', rul_file)\n","true_rul = pd.read_csv(rul_dataset_path, delimiter='\\s+', header=None)\n","\n"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"QmLL2dWa_O_z"},"outputs":[],"source":["def process_targets(data_length, early_rul = None):\n","    \"\"\"\n","    Takes datalength and earlyrul as input and\n","    creates target rul.\n","    \"\"\"\n","    if early_rul == None:\n","        return np.arange(data_length-1, -1, -1)\n","    else:\n","        early_rul_duration = data_length - early_rul\n","        if early_rul_duration <= 0:\n","            return np.arange(data_length-1, -1, -1)\n","        else:\n","            return np.append(early_rul*np.ones(shape = (early_rul_duration,)), np.arange(early_rul-1, -1, -1))"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"DcmTSjgu_O_z"},"outputs":[],"source":["def process_input_data_with_targets(input_data, target_data = None, window_length = 1, shift = 1):\n","    \"\"\"Depending on values of window_length and shift, this function generates batchs of data and targets\n","    from input_data and target_data.\n","\n","    Number of batches = np.floor((len(input_data) - window_length)/shift) + 1\n","\n","    **We don't check input dimensions uisng exception handling. So readers should be careful while using these\n","    functions. If input data are not of desired dimension, either error occurs or something undesirable is\n","    produced as output.**\n","\n","    Arguments:\n","        input_data: input data to function (Must be 2 dimensional)\n","        target_data: input rul values (Must be 1D array)s\n","        window_length: window length of data\n","        shift: Distance by which the window moves for next batch. This is closely related to overlap\n","               between data. For example, if window length is 30 and shift is 1, there is an overlap of\n","               29 data points between two consecutive batches.\n","\n","    \"\"\"\n","    num_batches = np.int64(np.floor((len(input_data) - window_length)/shift)) + 1\n","    num_features = input_data.shape[1]\n","    output_data = np.repeat(np.nan, repeats = num_batches * window_length * num_features).reshape(num_batches, window_length,\n","                                                                                                  num_features)\n","    if target_data is None:\n","        for batch in range(num_batches):\n","            output_data[batch,:,:] = input_data[(0+shift*batch):(0+shift*batch+window_length),:]\n","        return output_data\n","    else:\n","        output_targets = np.repeat(np.nan, repeats = num_batches)\n","        for batch in range(num_batches):\n","            output_data[batch,:,:] = input_data[(0+shift*batch):(0+shift*batch+window_length),:]\n","            output_targets[batch] = target_data[(shift*batch + (window_length-1))]\n","        return output_data, output_targets"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"ciAouPKu_O_0"},"outputs":[],"source":["def process_test_data(test_data_for_an_engine, window_length, shift, num_test_windows = 1):\n","    \"\"\" This function takes test data for an engine as first input. The next two inputs\n","    window_length and shift are same as other functins.\n","\n","    Finally it takes num_test_windows as the last input. num_test_windows sets how many examplles we\n","    want from test data (from last). By default it extracts only the last example.\n","\n","    The function return last examples and number of last examples (a scaler) as output.\n","    We need the second output later. If we are extracting more than 1 last examples, we have to\n","    average their prediction results. The second scaler halps us do just that.\n","    \"\"\"\n","    max_num_test_batches = np.int64(np.floor((len(test_data_for_an_engine) - window_length)/shift)) + 1\n","    if max_num_test_batches < num_test_windows:\n","        required_len = (max_num_test_batches -1)* shift + window_length\n","        batched_test_data_for_an_engine = process_input_data_with_targets(test_data_for_an_engine[-required_len:, :],\n","                                                                          target_data = None,\n","                                                                          window_length = window_length, shift = shift)\n","        return batched_test_data_for_an_engine, max_num_test_batches\n","    else:\n","        required_len = (num_test_windows - 1) * shift + window_length\n","        batched_test_data_for_an_engine = process_input_data_with_targets(test_data_for_an_engine[-required_len:, :],\n","                                                                          target_data = None,\n","                                                                          window_length = window_length, shift = shift)\n","        return batched_test_data_for_an_engine, num_test_windows"]},{"cell_type":"markdown","metadata":{"id":"7JsIQK8q_O_0"},"source":["There are two scaling strategies that we can employ. We can scale columnwise, ignoring individual engine based scaling. Or we can scale enginewise."]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":616,"status":"ok","timestamp":1689020259402,"user":{"displayName":"Alberto Moccardi","userId":"09120262365331070077"},"user_tz":-120},"id":"lYGHLBXU_O_0","outputId":"fae3ed38-4939-4f73-ea50-86b74fc492eb"},"outputs":[{"name":"stdout","output_type":"stream","text":["Processed trianing data shape:  (17731, 30, 14)\n","Processed training ruls shape:  (17731,)\n","Processed test data shape:  (497, 30, 14)\n","True RUL shape:  (100,)\n"]}],"source":["\n","window_length = 30\n","shift = 1\n","early_rul = 125\n","processed_train_data = []\n","processed_train_targets = []\n","\n","# How many test windows to take for each engine. If set to 1 (this is the default), only last window of test data for\n","# each engine is taken. If set to a different number, that many windows from last are taken.\n","# Final output is the average output of all windows.\n","num_test_windows = 5\n","processed_test_data = []\n","num_test_windows_list = []\n","\n","columns_to_be_dropped = [0,1,2,3,4,5,9,10,14,20,22,23]\n","\n","train_data_first_column = train_data[0]\n","test_data_first_column = test_data[0]\n","\n","# Scale data for all engines\n","scaler = StandardScaler()\n","train_data = scaler.fit_transform(train_data.drop(columns = columns_to_be_dropped))\n","test_data = scaler.transform(test_data.drop(columns = columns_to_be_dropped))\n","\n","train_data = pd.DataFrame(data = np.c_[train_data_first_column, train_data])\n","test_data = pd.DataFrame(data = np.c_[test_data_first_column, test_data])\n","\n","num_train_machines = len(train_data[0].unique())\n","num_test_machines = len(test_data[0].unique())\n","\n","# Process training and test data sepeartely as number of engines in training and test set may be different.\n","# As we are doing scaling for full dataset, we are not bothered by different number of engines in training and test set.\n","\n","# Process trianing data\n","for i in np.arange(1, num_train_machines + 1):\n","    temp_train_data = train_data[train_data[0] == i].drop(columns = [0]).values\n","\n","    # Verify if data of given window length can be extracted from training data\n","    if (len(temp_train_data) < window_length):\n","        print(\"Train engine {} doesn't have enough data for window_length of {}\".format(i, window_length))\n","        raise AssertionError(\"Window length is larger than number of data points for some engines. \"\n","                             \"Try decreasing window length.\")\n","\n","    temp_train_targets = process_targets(data_length = temp_train_data.shape[0], early_rul = early_rul)\n","    data_for_a_machine, targets_for_a_machine = process_input_data_with_targets(temp_train_data, temp_train_targets,\n","                                                                                window_length = window_length, shift = shift)\n","\n","    processed_train_data.append(data_for_a_machine)\n","    processed_train_targets.append(targets_for_a_machine)\n","\n","processed_train_data = np.concatenate(processed_train_data)\n","processed_train_targets = np.concatenate(processed_train_targets)\n","\n","# Process test data\n","for i in np.arange(1, num_test_machines + 1):\n","    temp_test_data = test_data[test_data[0] == i].drop(columns = [0]).values\n","\n","    # Verify if data of given window length can be extracted from test data\n","    if (len(temp_test_data) < window_length):\n","        print(\"Test engine {} doesn't have enough data for window_length of {}\".format(i, window_length))\n","        raise AssertionError(\"Window length is larger than number of data points for some engines. \"\n","                             \"Try decreasing window length.\")\n","\n","    # Prepare test data\n","    test_data_for_an_engine, num_windows = process_test_data(temp_test_data, window_length = window_length, shift = shift,\n","                                                             num_test_windows = num_test_windows)\n","\n","    processed_test_data.append(test_data_for_an_engine)\n","    num_test_windows_list.append(num_windows)\n","\n","processed_test_data = np.concatenate(processed_test_data)\n","true_rul = true_rul[0].values\n","\n","# Shuffle training data\n","index = np.random.permutation(len(processed_train_targets))\n","processed_train_data, processed_train_targets = processed_train_data[index], processed_train_targets[index]\n","\n","print(\"Processed trianing data shape: \", processed_train_data.shape)\n","print(\"Processed training ruls shape: \", processed_train_targets.shape)\n","print(\"Processed test data shape: \", processed_test_data.shape)\n","print(\"True RUL shape: \", true_rul.shape)"]},{"cell_type":"markdown","metadata":{"id":"JhC0gYKO_O_1"},"source":["#### Training and validation split\n","\n","We will take 20% of training data (sampled randomly) as our validation set. We will monitor the training of our model using the validation set."]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":425,"status":"ok","timestamp":1689020262050,"user":{"displayName":"Alberto Moccardi","userId":"09120262365331070077"},"user_tz":-120},"id":"tOPBNOpT_O_1","outputId":"043b58f4-ad95-40b6-a96d-f0f3933074be"},"outputs":[{"name":"stdout","output_type":"stream","text":["Processed train data shape:  (14184, 30, 14)\n","Processed validation data shape:  (3547, 30, 14)\n","Processed train targets shape:  (14184,)\n","Processed validation targets shape:  (3547,)\n"]}],"source":["import torch\n","from torch.utils.data import Dataset, DataLoader\n","processed_train_data, processed_val_data, processed_train_targets, processed_val_targets = train_test_split(processed_train_data,\n","                                                                                                            processed_train_targets,\n","                                                                                                            test_size = 0.2,\n","                                                                                                            random_state = 83)\n","print(\"Processed train data shape: \", processed_train_data.shape)\n","print(\"Processed validation data shape: \", processed_val_data.shape)\n","print(\"Processed train targets shape: \", processed_train_targets.shape)\n","print(\"Processed validation targets shape: \", processed_val_targets.shape)\n","\n","# 创建自定义的数据集类\n","class CustomDataset(Dataset):\n","    def __init__(self, data, targets):\n","        self.data = torch.from_numpy(data).float()  # Convert data to torch.float32\n","        self.targets = torch.from_numpy(targets).float()  # Convert targets to torch.float32\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, idx):\n","        return self.data[idx], self.targets[idx]\n","\n","# 将处理后的训练数据和目标数据转换为数据集对象\n","train_dataset = CustomDataset(processed_train_data, processed_train_targets)\n","val_dataset = CustomDataset(processed_val_data, processed_val_targets)\n","\n","# 创建训练数据加载器和验证数据加载器\n","batch_size = 32\n","train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","val_loader = DataLoader(val_dataset, batch_size=batch_size)\n","\n","# 使用示例：\n"]},{"cell_type":"markdown","metadata":{"id":"920ET2Pr_O_1"},"source":["#### LSTM model"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"SaIZ8P05_O_1"},"outputs":[],"source":["import torch\n","from torch import nn\n","import torch.optim as optim\n","\n","\n","class Net(nn.Module):\n","    def __init__(self):\n","        super(Net, self).__init__()\n","\n","        self.lstm1 =  KANxLSTM(14, 2, 1, \"ms\", batch_first=True, proj_factor_slstm=4/3, proj_factor_mlstm=2) #input_size, head_size, num_heads, proj_factor=2\n","\n","        self.fc1 = nn.Linear(420, 32)\n","        self.dr = nn.Dropout(0.5)\n","        self.fc3 = nn.Linear(32, 1)\n","\n","    def forward(self, x):\n","        x, _ = self.lstm1(x)\n","        #print(x.shape)\n","        x = torch.tanh(x.reshape(x.shape[0], -1))\n","        x = self.dr(x)\n","        x = self.fc1(x)\n","\n","        x = torch.relu(x)\n","        x = self.fc3(x)\n","        return x\n","\n","def create_compiled_model():\n","    model = Net()\n","    loss_fn = nn.MSELoss()\n","    optimizer = optim.Adam(model.parameters(), lr=0.01)\n","    return model, loss_fn, optimizer"]},{"cell_type":"markdown","metadata":{"id":"uQAQkJ3K_O_1"},"source":["We will use a `Learning rate scheduler` callback that will change the learning rate after 5 epochs."]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 0/119\n","----------\n","train Loss: 538.6156\n","val Loss: 245.9023\n","Epoch 10/119\n","----------\n","train Loss: 273.0573\n","val Loss: 197.6735\n","Epoch 20/119\n","----------\n","train Loss: 246.4821\n","val Loss: 179.9354\n","Epoch 30/119\n","----------\n","train Loss: 181.1724\n","val Loss: 125.0932\n"]}],"source":["from torch.optim import lr_scheduler\n","\n","def train_model(model, loss_fn, optimizer, scheduler, num_epochs=30):\n","    for epoch in range(num_epochs):\n","        if epoch % 10 == 0:\n","            print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n","            print('-' * 10)\n","\n","        # Each epoch has a training and validation phase\n","        for phase in ['train', 'val']:\n","            if phase == 'train':\n","                model.train()  # Set model to training mode\n","            else:\n","                model.eval()   # Set model to evaluate mode\n","\n","            running_loss = 0.0\n","            running_corrects = 0\n","\n","            # Iterate over data.\n","            for inputs, labels in dataloaders[phase]:\n","                inputs = inputs.to(device)\n","                labels = labels.to(device)\n","                model.to(device)\n","                # zero the parameter gradients\n","                optimizer.zero_grad()\n","\n","                # forward\n","                # track history if only in train\n","                with torch.set_grad_enabled(phase == 'train'):\n","                    outputs = model(inputs)\n","                    loss = loss_fn(outputs.squeeze(), labels)\n","\n","                    # backward + optimize only if in training phase\n","                    if phase == 'train':\n","                        loss.backward()\n","                        optimizer.step()\n","\n","                # statistics\n","                running_loss += loss.item() * inputs.size(0)\n","\n","\n","            if phase == 'train':\n","                scheduler.step()\n","\n","            epoch_loss = running_loss / dataset_sizes[phase]\n","\n","            if epoch % 10 == 0:\n","                print('{} Loss: {:.4f}'.format(\n","                phase, epoch_loss))\n","\n","    return model\n","\n","model, loss_fn, optimizer = create_compiled_model()\n","exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1)\n","dataloaders = {\"train\": train_loader, \"val\": val_loader}\n","dataset_sizes = {\"train\": len(train_dataset), \"val\": len(val_dataset)}\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","model = train_model(model, loss_fn, optimizer, exp_lr_scheduler, num_epochs=120)"]},{"cell_type":"markdown","metadata":{"id":"3yvHkjY6_O_2"},"source":["Why did we run the model only for 10 epochs, even though the validation loss seems to be decreasing? Well, while training this model for more epochs, we previously observed that it is possible to decrease the validation loss to a very small number. But in that case, our actual test loss is not that great. This is because our model is overfitting the validation dataset. So to get a good test performance, we should stop our training at an intermediate value of the validation loss. We chose 10 epochs as that gives a good enough test error."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1231,"status":"ok","timestamp":1689020310245,"user":{"displayName":"Alberto Moccardi","userId":"09120262365331070077"},"user_tz":-120},"id":"VJNrc9yF_O_2","outputId":"2531fc72-56d1-41f0-e67e-d41aa676a131"},"outputs":[],"source":["model.eval()  # Set the model to evaluation mode\n","with torch.no_grad():  # Turn off gradients for prediction\n","    data = torch.from_numpy(processed_test_data).float().to(device)  # Convert the data to the correct type and device\n","    outputs = model(data)  # Forward pass\n","    rul_pred = outputs.cpu().numpy().reshape(-1)  \n","preds_for_each_engine = np.split(rul_pred, np.cumsum(num_test_windows_list)[:-1])\n","mean_pred_for_each_engine = [np.average(ruls_for_each_engine, weights = np.repeat(1/num_windows, num_windows))\n","                             for ruls_for_each_engine, num_windows in zip(preds_for_each_engine, num_test_windows_list)]\n","RMSE = np.sqrt(mean_squared_error(true_rul, mean_pred_for_each_engine))\n","print(\"RMSE: \", RMSE)"]},{"cell_type":"markdown","metadata":{"id":"Z8_osW9W_O_2"},"source":["We will now compute the RMSE by taking only last example of each engine."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1689020312026,"user":{"displayName":"Alberto Moccardi","userId":"09120262365331070077"},"user_tz":-120},"id":"SHPCueKn_O_3","outputId":"230e3c60-f6fd-4ade-8867-b5399f504080"},"outputs":[],"source":["indices_of_last_examples = np.cumsum(num_test_windows_list) - 1\n","preds_for_last_example = np.concatenate(preds_for_each_engine)[indices_of_last_examples]\n","\n","RMSE_new = np.sqrt(mean_squared_error(true_rul, preds_for_last_example))\n","print(\"RMSE (Taking only last examples): \", RMSE_new)"]},{"cell_type":"markdown","metadata":{"id":"ijU4Ts_8_O_3"},"source":["If you are not convinced by above calculations, take a look at the last section of [this notebook](https://github.com/biswajitsahoo1111/rul_codes_open/blob/master/notebooks/cmapss_notebooks/CMAPSS_FD001_xgboost_piecewise_linear_degradation_model.ipynb)."]},{"cell_type":"markdown","metadata":{"id":"788VGW7c_O_3"},"source":["For CMAPSS data, along with RMSE another metric (S-score) is usually reported in literature. S-score is defined as:\n","\n","$$S= \\sum_{i=1}^N{s_i}$$\n","\n","where,\n","\n","$$\n","\\begin{equation}\n","    s_i=\n","    \\begin{cases}\n","      (e^{-\\frac{d_i}{13}})-1, & \\text{for}\\ d_i < 1 \\\\\n","      (e^{\\frac{d_i}{10}})-1, & \\text{for}\\ d_i \\geq 1\\\\\n","    \\end{cases}\n","  \\end{equation}\n","  $$\n","  \n","We can compute the S-metric as follows."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"874dehkW_O_3"},"outputs":[],"source":["def compute_s_score(rul_true, rul_pred):\n","    \"\"\"\n","    Both rul_true and rul_pred should be 1D numpy arrays.\n","    \"\"\"\n","    diff = rul_pred - rul_true\n","    return np.sum(np.where(diff < 0, np.exp(-diff/13)-1, np.exp(diff/10)-1))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":415,"status":"ok","timestamp":1689020317363,"user":{"displayName":"Alberto Moccardi","userId":"09120262365331070077"},"user_tz":-120},"id":"02Mc-wnn_O_3","outputId":"e9a33117-1a79-4848-dc55-e4c2bb237c26"},"outputs":[],"source":["s_score = compute_s_score(true_rul, preds_for_last_example)\n","print(\"S-score: \", s_score)"]},{"cell_type":"markdown","metadata":{"id":"itHMCLGOHhKq"},"source":["# Results FD001"]},{"cell_type":"markdown","metadata":{"id":"YG4dX8XR_O_4"},"source":["It is very likely that readers may get sligtly different results while running this notebook on their system. This happens because of the nondeterministic nature of some deep learning operations and dependence of libraries like `Tensorflow` on computer architecture. Therefore, to make our results reproducible, we also share saved models of all our notebooks. All saved models can be found [here](https://github.com/biswajitsahoo1111/rul_codes_open/tree/master/saved_models/cmapss). A notebook describing the procedure to use the saved models can be found [here](https://github.com/biswajitsahoo1111/rul_codes_open/blob/master/notebooks/cmapss_notebooks/CMAPSS_using_saved_model_deep_learning.ipynb). As a final note remember that hyperparameter tuning is more of an art than science. It is possible to obtain better results than what has been obtained here by choosing better set of hyperparameters.\n","\n","For other reproducible results on RUL, interested readers can visit my [project page](https://biswajitsahoo1111.github.io/rul_codes_open)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BLE4l0Uo7Aue"},"outputs":[],"source":["def compute_s_score(rul_true, rul_pred):\n","    \"\"\"\n","    Both rul_true and rul_pred should be 1D numpy arrays.\n","    \"\"\"\n","    diff = rul_pred - rul_true\n","    return np.sum(np.where(diff < 0, np.exp(-diff/13)-1, np.exp(diff/10)-1))"]},{"cell_type":"markdown","metadata":{"id":"jEy2cOxHdOpX"},"source":["#### Last 5 preds"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1689020322073,"user":{"displayName":"Alberto Moccardi","userId":"09120262365331070077"},"user_tz":-120},"id":"LroOgNS1Z84I","outputId":"4cf6d146-27f0-484e-c920-c15f37f40ab8"},"outputs":[],"source":["model.eval()  # Set the model to evaluation mode\n","with torch.no_grad():  # Turn off gradients for prediction\n","    data = torch.from_numpy(processed_test_data).float().to(device)  # Convert the data to the correct type and device\n","    outputs = model(data)  # Forward pass\n","    rul_pred = outputs.cpu().numpy().reshape(-1)  \n","preds_for_each_engine = np.split(rul_pred, np.cumsum(num_test_windows_list)[:-1])\n","mean_pred_for_each_engine = [np.average(ruls_for_each_engine, weights = np.repeat(1/num_windows, num_windows))\n","                             for ruls_for_each_engine, num_windows in zip(preds_for_each_engine, num_test_windows_list)]\n","RMSE = np.sqrt(mean_squared_error(true_rul, mean_pred_for_each_engine))\n","print(\"RMSE: \", RMSE)\n","\n","MAE = (mean_absolute_error(true_rul, mean_pred_for_each_engine))\n","print(\"MAE\", MAE)\n","\n","MAE_perc= mean_absolute_percentage_error(true_rul,mean_pred_for_each_engine)\n","print(\"MAE   \" , MAE_perc)\n","\n","\n","s_score = compute_s_score(true_rul, mean_pred_for_each_engine)\n","print(\"S-score: \", s_score)"]},{"cell_type":"markdown","metadata":{"id":"pX9Kt2LrZ84J"},"source":["We will now compute the RMSE by taking only last example of each engine."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":587,"status":"ok","timestamp":1689020325790,"user":{"displayName":"Alberto Moccardi","userId":"09120262365331070077"},"user_tz":-120},"id":"daLvSsNTZ84K","outputId":"23f3b53e-6f7d-4e11-b133-df73a4bb17a2"},"outputs":[],"source":["indices_of_last_examples = np.cumsum(num_test_windows_list) - 1\n","preds_for_last_example = np.concatenate(preds_for_each_engine)[indices_of_last_examples]\n","\n","RMSE_new = np.sqrt(mean_squared_error(true_rul, preds_for_last_example))\n","print(\"RMSE (Taking only last examples): \", RMSE_new)\n","MAE_new = mean_absolute_error(true_rul,preds_for_last_example)\n","print(\"% MAE only last examples  \" ,MAE_new)\n","\n","MAE_perc= mean_absolute_percentage_error(true_rul,preds_for_last_example)\n","print(\"% MAE only last examples  \" , MAE_perc)\n","s_score = compute_s_score(true_rul, preds_for_last_example)\n","print(\"S-score: \", s_score)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":472},"executionInfo":{"elapsed":764,"status":"ok","timestamp":1689015053051,"user":{"displayName":"Alberto Moccardi","userId":"09120262365331070077"},"user_tz":-120},"id":"jBetmY8nRE1s","outputId":"30b71709-0bee-435b-89ca-19915416fb87"},"outputs":[],"source":["\n","\n","def plot_series(series1, series2):\n","    # Convert series to lists\n","    series1_list = series1.tolist()\n","    series2_list = series2.tolist()\n","\n","    # Create a figure and axes\n","    fig, ax = plt.subplots()\n","\n","    # Plot series1 as a line plot\n","    ax.plot(series1_list, label='prediction')\n","\n","    # Plot series2 as a line plot\n","    ax.plot(series2_list, label='true RUL')\n","\n","    # Add labels and title\n","    ax.set_xlabel('X-axis')\n","    ax.set_ylabel('Y-axis')\n","    ax.set_title('Line Plot')\n","\n","    # Add legend\n","    ax.legend()\n","\n","    # Show the plot\n","    plt.show()\n","plot_series(true_rul, preds_for_last_example)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":718},"executionInfo":{"elapsed":674,"status":"ok","timestamp":1689015053723,"user":{"displayName":"Alberto Moccardi","userId":"09120262365331070077"},"user_tz":-120},"id":"WxnctiCuRE1s","outputId":"07b025dd-cd53-40ff-ee21-e3b5a22907d7"},"outputs":[],"source":["import seaborn as sns\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","def plot_series(series1, series2):\n","    # Convert series to lists\n","    series1_list = series1.tolist()\n","    series2_list = series2.tolist()\n","\n","    # Create a figure and axes\n","    plt.figure(figsize=(10, 8))\n","\n","    # Create dataframes for each series\n","    df1 = pd.DataFrame(series1_list, columns=['value'])\n","    df1['type'] = 'Prediction'\n","    df2 = pd.DataFrame(series2_list, columns=['value'])\n","    df2['type'] = 'True RUL'\n","\n","    # Concatenate the dataframes\n","    df = pd.concat([df1, df2])\n","\n","    # Calculate the range of real values in the series\n","    min_value = min(min(series1_list), min(series2_list))\n","    max_value = max(max(series1_list), max(series2_list))\n","\n","    # Create a violin plot with split, specifying the range of values\n","    sns.violinplot(x='type', y='value', data=df, split=True, inner='quartile', palette=\"Set2\",\n","                   cut=0, scale='width', bw='silverman', width=0.8, saturation=0.8, trim=True,\n","                   range=(min_value, max_value))\n","\n","    # Create labels\n","    plt.xlabel('Series')\n","    plt.ylabel('Remaining Useful Life (RUL)')\n","    plt.title(' Violin Plot of Predictions and True RUL')\n","\n","    # Show the plot\n","    plt.show()\n","\n","\n","# Call the function\n","plot_series(true_rul, preds_for_last_example)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":807},"executionInfo":{"elapsed":753,"status":"ok","timestamp":1689015054469,"user":{"displayName":"Alberto Moccardi","userId":"09120262365331070077"},"user_tz":-120},"id":"a5bF3SzLRE1s","outputId":"53aafda7-1a64-4e36-92de-1867a8b95f63"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import seaborn as sns\n","import numpy as np\n","\n","def plot_series(series1, series2):\n","    # Convert series to lists\n","    series1_list = series1.tolist()\n","    series2_list = series2.tolist()\n","\n","    # Create a figure and axes\n","    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10, 8))\n","\n","    # Use seaborn styles\n","    sns.set_style(\"whitegrid\")\n","\n","    # Plot series1 as a line plot\n","    ax1.plot(series1_list, label='prediction', marker='o', linestyle='-', color='b')\n","\n","    # Plot series2 as a line plot\n","    ax1.plot(series2_list, label='true RUL', marker='o', linestyle='--', color='r')\n","\n","    # Add labels and title\n","    ax1.set_xlabel('Units')\n","    ax1.set_ylabel('Remaining Useful Life (RUL)')\n","    ax1.set_title('Predicted RUL vs True Rul')\n","\n","    # Increase the line width\n","    for line in ax1.lines:\n","        line.set_linewidth(2)\n","\n","    # Add legend\n","    ax1.legend()\n","\n","    # Calculate difference between series1 and series2\n","    diff = np.array(series1_list) - np.array(series2_list)\n","\n","    # Create a bar plot for differences\n","    ax2.bar(range(len(diff)), diff, color='purple')\n","\n","    # Add labels and title\n","    ax2.set_xlabel('Units')\n","    ax2.set_ylabel('Remaining Useful Life (RUL)')\n","    ax2.set_title('Difference Between Predictions and True RUL')\n","\n","    # Adjust space between the plots\n","    plt.tight_layout()\n","\n","    # Show the plots\n","    plt.show()\n","\n","# Call the function\n","plot_series(true_rul, preds_for_last_example)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ay6qKwbjdYWL"},"outputs":[],"source":["from sklearn.metrics import mean_absolute_error\n","\n","def evaluate_critical_mae(predictions, true_rul):\n","    # Convert lists to numpy arrays for element-wise operations\n","    predictions = np.array(predictions)\n","    true_rul = np.array(true_rul)\n","\n","    # Find the indices where true RUL is less than 15\n","    critical_indices = np.where(true_rul < 15)\n","\n","    # Extract the critical predictions and true RUL\n","    critical_predictions = predictions[critical_indices]\n","    critical_true_rul = true_rul[critical_indices]\n","\n","    # Calculate the MAE\n","    mae = mean_absolute_error(critical_true_rul, critical_predictions)\n","\n","    return mae\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":429,"status":"ok","timestamp":1689020380468,"user":{"displayName":"Alberto Moccardi","userId":"09120262365331070077"},"user_tz":-120},"id":"JJuLqJ2xdYWM","outputId":"7e56c3aa-6b82-47f8-8501-92a76ee970bc"},"outputs":[],"source":["mae = evaluate_critical_mae(preds_for_last_example, true_rul)\n","print(f\"The MAE for critical predictions is: {mae}\")\n"]},{"cell_type":"markdown","metadata":{"id":"f0WLf6MyhO7V"},"source":["# FD001"]},{"cell_type":"markdown","metadata":{"id":"kRMYnu4MiXfJ"},"source":["last 5"]},{"cell_type":"markdown","metadata":{"id":"UCzuJCKLgfFU"},"source":["| Metric | Value                 |\n","|--------|-----------------------|\n","| RMSE   | 14.924283414675442    |\n","| MAE    | 11.69177043247223     |\n","| MAE    | 0.2015629544201476    |\n","| S-score| 433.61579520912676    |\n"]},{"cell_type":"markdown","metadata":{"id":"L_ZGr2F4iZo1"},"source":["last example"]},{"cell_type":"markdown","metadata":{"id":"rgBD_gl0hMmB"},"source":["| Metric                            | Value                 |\n","|-----------------------------------|-----------------------|\n","| RMSE (Taking only last examples)  | 15.109726898982043    |\n","| % MAE only last examples          | 11.239905338287354    |\n","| % MAE only last examples          | 0.1641893299713881    |\n","| S-score                           | 420.54334755535365    |\n"]},{"cell_type":"markdown","metadata":{"id":"vWyfC3tXjsrr"},"source":["| Metric                            | Last 5 Example           | Last  Example        |\n","|-----------------------------------|-----------------------|------------------------|\n","| RMSE                              | 14.924283414675442    | 15.109726898982043     |\n","| MAE                               | 11.69177043247223     | 11.239905338287354     |\n","| MAE                               | 0.2015629544201476    | 0.1641893299713881     |\n","| S-score                           | 433.61579520912676    | 420.54334755535365     |\n"]},{"cell_type":"markdown","metadata":{"id":"u8WU6d6yhRll"},"source":["# FD002"]},{"cell_type":"markdown","metadata":{"id":"jZ61fCpRie5p"},"source":["last 5"]},{"cell_type":"markdown","metadata":{"id":"D1cVEd1shTzJ"},"source":["| Metric | Value                 |\n","|--------|-----------------------|\n","| RMSE   | 25.969482183253387    |\n","| MAE    | 18.094825164875928    |\n","| MAE    | 0.3145206386108706    |\n","| S-score| 12846.982989204538    |\n"]},{"cell_type":"markdown","metadata":{"id":"agKmY41tigkJ"},"source":["last examples"]},{"cell_type":"markdown","metadata":{"id":"VKKwd4mHhfX6"},"source":["| Metric                            | Value                 |\n","|-----------------------------------|-----------------------|\n","| RMSE  | 25.820265111799944    |\n","| MAE           | 17.886208949402032    |\n","| % MAE          | 0.29021528456382106   |\n","| S-score                           | 10833.431179482766    |\n"]},{"cell_type":"markdown","metadata":{"id":"SWbSZ20cjBcM"},"source":["| Metric                            | Last 5           | Last Examples        |\n","|-----------------------------------|-----------------------|------------------------|\n","| RMSE                              | 25.969482183253387    | 25.820265111799944     |\n","| MAE                               | 18.094825164875928    | 17.886208949402032     |\n","| MAE                               | 0.3145206386108706    | 0.29021528456382106    |\n","| S-score                           | 12846.982989204538    | 10833.431179482766    |\n"]},{"cell_type":"markdown","metadata":{"id":"myO1in6Yhpvu"},"source":["# fd003"]},{"cell_type":"markdown","metadata":{"id":"Al1rGl-7imW5"},"source":["last 5"]},{"cell_type":"markdown","metadata":{"id":"FGSKS8_6hzwQ"},"source":["| Metric                            | Value                 |\n","|-----------------------------------|-----------------------|\n","| RMSE (Taking only last examples)  | 13.79427836806829     |\n","| MAE only last examples          | 10.74395896434784     |\n","| % MAE only last examples          | 0.1779147971993347    |\n","| S-score                           | 257.0967840795584     |\n"]},{"cell_type":"markdown","metadata":{"id":"CbWQrM4xip6V"},"source":["last"]},{"cell_type":"markdown","metadata":{"id":"rcRpiXiThq8o"},"source":["| Metric | Value                 |\n","|--------|-----------------------|\n","| RMSE   | 15.141513175312488    |\n","| MAE    | 11.587211685180664    |\n","| MAE    | 0.2114921732809048   |\n","| S-score| 375.1661445415284    |\n"]},{"cell_type":"markdown","metadata":{"id":"Hg8AXx1YjPRR"},"source":["| Metric                            | Last 5 Example           | Last  Example        |\n","|-----------------------------------|-----------------------|------------------------|\n","| RMSE  | 13.79427836806829     | 15.141513175312488     |\n","| MAE          | 10.74395896434784     | 11.587211685180664     |\n","| % MAE           | 0.1779147971993347    | 0.2114921732809048     |\n","| S-score                           | 257.0967840795584     | 375.1661445415284     |\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Dr73ezyjjOqV"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"YBKOEsZch8ii"},"source":["#fd004"]},{"cell_type":"markdown","metadata":{"id":"BQhmDKoyiuob"},"source":["last 5"]},{"cell_type":"markdown","metadata":{"id":"3UeuLdlth98_"},"source":["| Metric | Value                 |\n","|--------|-----------------------|\n","| RMSE   | 29.38823677700239     |\n","| MAE    | 22.941654827902394    |\n","| MAE    | 0.43580475811149433   |\n","| S-score| 12748.783293038632    |\n"]},{"cell_type":"markdown","metadata":{"id":"F0fQsrazitlX"},"source":["last"]},{"cell_type":"markdown","metadata":{"id":"pWogDC8Th-u_"},"source":["| Metric                            | Value                 |\n","|-----------------------------------|-----------------------|\n","| RMSE (Taking only last examples)  | 29.435246281099328    |\n","| MAE (Taking only last example)    | 22.830334198090338    |\n","| % MAE only last examples          | 0.39199495157984415   |\n","| S-score                           | 12513.92265158481     |\n"]},{"cell_type":"markdown","metadata":{"id":"s6IJVPTIjgIJ"},"source":["| Metric                            | Last 5 Example           | Last  Examples        |\n","|-----------------------------------|-----------------------|------------------------|\n","| RMSE                              | 29.38823677700239     | 29.435246281099328     |\n","| MAE                               | 22.941654827902394    | 22.830334198090338     |\n","| MAE                               | 0.43580475811149433   | 0.39199495157984415    |\n","| S-score                           | 12748.783293038632    | 12513.92265158481     |\n"]},{"cell_type":"markdown","metadata":{"id":"apHP5DLnkKBb"},"source":["# Complete metrics"]},{"cell_type":"markdown","metadata":{"id":"gNApQXEZkMSt"},"source":["## FD001\n","\n","| Metric                            | Last 5 Example           | Last Example        |\n","|-----------------------------------|-----------------------|------------------------|\n","| RMSE                              | 14.924283414675442    | 15.109726898982043     |\n","| MAE                               | 11.69177043247223     | 11.239905338287354     |\n","| MAE                               | 0.2015629544201476    | 0.1641893299713881     |\n","| S-score                           | 433.61579520912676    | 420.54334755535365     |\n","\n","## FD002\n","\n","| Metric                            | Last 5           | Last Example        |\n","|-----------------------------------|-----------------------|------------------------|\n","| RMSE                              | 25.969482183253387    | 25.820265111799944     |\n","| MAE                               | 18.094825164875928    | 17.886208949402032     |\n","| MAE                               | 0.3145206386108706    | 0.29021528456382106    |\n","| S-score                           | 12846.982989204538    | 10833.431179482766    |\n","\n","## FD003\n","\n","| Metric                            | Last 5 Example           | Last Example        |\n","|-----------------------------------|-----------------------|------------------------|\n","| RMSE                              | 13.79427836806829     | 15.141513175312488     |\n","| MAE                               | 10.74395896434784     | 11.587211685180664     |\n","| % MAE                             | 0.1779147971993347    | 0.2114921732809048     |\n","| S-score                           | 257.0967840795584     | 375.1661445415284     |\n","\n","## FD004\n","\n","| Metric                            | Last 5 Example           | Last Examples        |\n","|-----------------------------------|-----------------------|------------------------|\n","| RMSE                              | 29.38823677700239     | 29.435246281099328     |\n","| MAE                               | 22.941654827902394    | 22.830334198090338     |\n","| MAE                               | 0.43580475811149433   | 0.39199495157984415    |\n","| S-score                           | 12748.783293038632    | 12513.92265158481     |\n"]},{"cell_type":"markdown","metadata":{"id":"XLfwePqmkuvY"},"source":["# Critical errors"]},{"cell_type":"markdown","metadata":{"id":"-k0St4N5kxYz"},"source":["| FD Group | MAE for Critical Predictions |\n","|----------|-----------------------------|\n","| FD001    | 1.119092305501302           |\n","| FD002    | 4.02860562394305            |\n","| FD003    | 3.9500357839796276          |\n","| FD004    | 9.075825423002243           |\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3nkwvjrdhAmW"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"A100","machine_shape":"hm","provenance":[{"file_id":"1-ROBmui5IvhALxN6Nlh6-yx0owcjqkJp","timestamp":1699389412808}],"toc_visible":true},"interpreter":{"hash":"510e49bc31fb65b0d041977739a3e5f5edf9f8cd04bc034d427b5346da960650"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":0}
